{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62e991e-cffc-46e4-92c4-d354bec75ba1",
   "metadata": {},
   "source": [
    "### Model Template:\n",
    "\n",
    "##### We're going to have loads of models flying around, so it will be really helpful if we can all write models like this so everything's standardised.\n",
    "\n",
    "##### Essentially, we want all of our prediction objects to have a \"train\" function (if necessary) and a \"predict\" function. \n",
    "\n",
    "##### What we'll do is for each epidemic under consideration, we'll split the data in two and pass the first part to the train function. The test function is given both the whole dataset (all_df) and the test dataset (test_df).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aeb335f5-cf79-4e39-b9d2-1b727683d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class Linear_Regressor:\n",
    "    \n",
    "    ###############################################\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Leave this one unchanged except for the model name!\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.needs_training = True \n",
    "        self.name = 'Demo'\n",
    "    \n",
    "    ##############################################\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    train_df will be a dataframe, with rows sorted in chronological order (most recent last).\n",
    "    \n",
    "    The dataframe will be of the form:\n",
    "    \n",
    "    Region |  Week  |  Cases\n",
    "    __________________________\n",
    "    Oxford |   23   |  19284\n",
    "    \n",
    "    \n",
    "    Note that the week simply refers to the week of the year (to allow for seasonality to be incorporated).\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    \n",
    "    def train(self, train_df):\n",
    "        self.needs_training = False ### Keep this here!\n",
    "        \n",
    "        ###### Process Data (we want an array with current, last week, and two weeks ago cases)\n",
    "        \n",
    "        \n",
    "        split_df = [group for _, group in train_df.groupby('Region')]\n",
    "\n",
    "\n",
    "        processed_data = np.zeros((len(train_df)-2*len(split_df),3))\n",
    "\n",
    "        curr_row = 0\n",
    "        for df in split_df:\n",
    "            df['Back1'] = df['Cases'].shift(periods = 1)\n",
    "            df['Back2'] = df['Cases'].shift(periods = 2)\n",
    "            df = df.dropna()\n",
    "            processed_data[curr_row:curr_row + len(df)] = df[['Cases','Back1','Back2']].to_numpy()\n",
    "            curr_row += len(df)\n",
    "\n",
    "            \n",
    "        #### Our model is current = c[0]*last_week + c[1]*two_weeks_ago\n",
    "            \n",
    "        def Loss(c):\n",
    "\n",
    "            return np.sum(np.square(c[0]*processed_data[:,1] + c[1]*processed_data[:,2] - processed_data[:,0]))\n",
    "\n",
    "        #### Store trained parameter for prediction function\n",
    "        \n",
    "        self.c = minimize(Loss,np.ones(2)).x \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    There should be no outputs from train_df\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    test_df and all_df will be the same structure as train_df\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def predict(self, test_df,all_df,weeks_ahead):\n",
    "        dfout_train,test_df,all_df = ILI_Data()\n",
    "\n",
    "        all_df['Ind'] = np.arange(len(all_df)) ### Add index so we can map back our predictions later\n",
    "\n",
    "\n",
    "        ###### Process Data (we want an array with current, last week, and two weeks ago cases)\n",
    "\n",
    "        split_df = [group for _, group in all_df.groupby('Region')]\n",
    "\n",
    "\n",
    "        processed_data = np.zeros((len(all_df)-len(split_df),3))\n",
    "\n",
    "        curr_row = 0\n",
    "        for df in split_df:\n",
    "            df['Back1'] = df['Cases'].shift(periods = 1)\n",
    "            df = df.dropna()\n",
    "            processed_data[curr_row:curr_row + len(df)] = df[['Ind','Back1','Cases']].to_numpy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            curr_row += len(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #### Perform Forecasts\n",
    "\n",
    "        outputs_temp = np.zeros((len(processed_data),weeks_ahead+3))\n",
    "        outputs_temp[:,:3] = processed_data\n",
    "        for ahead in range(3,3+weeks_ahead):\n",
    "            outputs_temp[:,ahead] = self.c[1]*outputs_temp[:,ahead-2] + self.c[0]*outputs_temp[:,ahead-1]\n",
    "\n",
    "        #print(outputs_temp[:,1:])\n",
    "        #print(outputs_temp[:,0])\n",
    "        #### Final Outputs (on all data)\n",
    "\n",
    "        outputs_final = np.zeros((len(all_df),weeks_ahead))\n",
    "        outputs_final[outputs_temp[:,0].astype(int)] = outputs_temp[:,3:]\n",
    "\n",
    "\n",
    "        ##### Trim to test data\n",
    "        columns = []\n",
    "        for ahead in range(weeks_ahead):\n",
    "            all_df['Prediction ' + str(ahead+1)] = outputs_final[:,ahead]\n",
    "            columns.append('Prediction ' + str(ahead+1))\n",
    "\n",
    "        test_df = pd.merge(test_df,all_df[columns],left_index=True,right_index=True)\n",
    "        \n",
    "        return test_df\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    The outputs should be a df with predictions added to test_df as the rightmost columns \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ################################################\n",
    "    def name(self):\n",
    "        \n",
    "        return model.name\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0888854d-644c-49bc-9341-94b587da6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process_Scores(predictions,dfout_test,weeks_ahead,name):\n",
    "    to_append = [name]\n",
    "    dfout_test['Ind'] = np.arange(len(dfout_test))\n",
    "    true_data = np.zeros((len(dfout_test),weeks_ahead))\n",
    "    \n",
    "    split_df = [group for _, group in dfout_test.groupby('Region')]\n",
    "    curr_row = 0\n",
    "    for df in split_df:\n",
    "        for ahead in range(weeks_ahead):\n",
    "            df['Forward '+ str(ahead+1)] = df['Cases'].shift(periods = -ahead-1)\n",
    "        df = df.fillna(-1)\n",
    "        true_data[df['Ind'].to_numpy().astype(int)] = df.to_numpy()[:,-weeks_ahead:]\n",
    "            \n",
    "            \n",
    "            \n",
    "        curr_row += len(df)\n",
    "    \n",
    "    \n",
    "    pred_data = predictions.to_numpy()[:,-weeks_ahead:].astype(float)\n",
    "    \n",
    "    for week in range(weeks_ahead):\n",
    "        \n",
    "        to_append.append(np.sqrt(np.mean(np.square(true_data[true_data[:,week] !=-1 ,week] - pred_data[true_data[:,week] !=-1 ,week] ))))\n",
    "        \n",
    "    return to_append\n",
    "\n",
    "\n",
    "\n",
    "def ILI_Data():\n",
    "    df = pd.read_csv('ILINet.csv',skiprows=1)[['REGION','YEAR','WEEK','ILITOTAL']]\n",
    "    df = df[df['ILITOTAL']!='X']\n",
    "    df_out = df[['REGION','WEEK','ILITOTAL','YEAR']]\n",
    "    df_out.columns = ['Region','Week','Cases','Year']\n",
    "    \n",
    "    \n",
    "    dfout_train = df_out[df_out['Year'] + df_out['Week']*0.01 < 2015.25]\n",
    "    \n",
    "    \n",
    "    dfout_test = df_out[(df_out['Year'] + df_out['Week']*0.01 >= 2015.25)&(df_out['Year'] + df_out['Week']*0.01 < 2019.25)]\n",
    "    \n",
    "    \n",
    "    return dfout_train[['Region','Week','Cases']],dfout_test[['Region','Week','Cases']],df_out[['Region','Week','Cases']]\n",
    "\n",
    "\n",
    "\n",
    "def ILI_Test(models,weeks_ahead):\n",
    "    \n",
    "    \n",
    "    #########################################################################\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This is the only thing we'll need to change to run this on a different dataset.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    dfout_train,dfout_test,dfout = ILI_Data()\n",
    "    \n",
    "    ##########################################################################\n",
    "    \n",
    "    #Creating Output Array\n",
    "    \n",
    "    output_predictions = []\n",
    "    \n",
    "    sc_array = ['Model']\n",
    "    for week in range(weeks_ahead):\n",
    "        sc_array.append('Week ' + str(week + 1))\n",
    "    \n",
    "    scores = [sc_array]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    #Testing models\n",
    "    \n",
    "    for model in models:\n",
    "        predictor = model()\n",
    "        \n",
    "        predictor.train(dfout_train)\n",
    "        \n",
    "        predictions = predictor.predict(dfout_test,dfout,weeks_ahead)\n",
    "\n",
    "        score_row = Process_Scores(predictions,dfout_test,weeks_ahead,predictor.name)\n",
    "        \n",
    "        scores.append(score_row)\n",
    "        \n",
    "        \n",
    "    ##############################################################################    \n",
    "        \n",
    "    scores = pd.DataFrame(scores[1:],columns = scores[0])\n",
    "\n",
    "    \n",
    "    return scores\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8bc15a6b-fe20-47cf-8c1c-7b42f79cbdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Week 1</th>\n",
       "      <th>Week 2</th>\n",
       "      <th>Week 3</th>\n",
       "      <th>Week 4</th>\n",
       "      <th>Week 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Demo</td>\n",
       "      <td>158.380565</td>\n",
       "      <td>269.6163</td>\n",
       "      <td>361.015936</td>\n",
       "      <td>431.983737</td>\n",
       "      <td>484.043647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model      Week 1    Week 2      Week 3      Week 4      Week 5\n",
       "0  Demo  158.380565  269.6163  361.015936  431.983737  484.043647"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [Linear_Regressor]\n",
    "ILI_Test(models,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4906eb2-8d75-44ac-ae8d-877bc664d988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
